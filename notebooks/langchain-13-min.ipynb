{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7RnyUOCJWmk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nLarge language models are powerful predictive models used to improve natural language processing tasks, such as language translation, text summarization, and sentiment analysis.'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run basic query with OpenAI wrapper\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "llm(\"explain large language models in one sentence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JtHgQ5XpJmgi"
      },
      "outputs": [],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, here's an example script that trains a simple neural network on simulated data:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "import tensorflow as tf\n",
            "\n",
            "# Generate simulated data\n",
            "x = np.random.rand(100, 10)\n",
            "y = np.random.randint(0, 2, size=(100, 1))\n",
            "\n",
            "# Define the neural network architecture\n",
            "model = tf.keras.Sequential([\n",
            "    tf.keras.layers.Dense(16, activation='relu', input_shape=(10,)),\n",
            "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
            "])\n",
            "\n",
            "# Compile the model\n",
            "model.compile(optimizer='adam',\n",
            "              loss='binary_crossentropy',\n",
            "              metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "model.fit(x, y, epochs=10, batch_size=32)\n",
            "\n",
            "# Evaluate the model on new data\n",
            "x_test = np.random.rand(10, 10)\n",
            "y_test = np.random.randint(0, 2, size=(10, 1))\n",
            "loss, accuracy = model.evaluate(x_test, y_test)\n",
            "print(f'Test loss: {loss}, Test accuracy: {accuracy}')\n",
            "```\n",
            "\n",
            "This script generates a simulated dataset of 100 samples with 10 features and a binary label. It then defines a simple neural network with one hidden layer of 16 units and a sigmoid output layer. The model is compiled with binary cross-entropy loss and trained for 10 epochs on the simulated data. Finally, the model is evaluated on a new simulated dataset of 10 samples and the test loss and accuracy are printed.\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert data scientist\"),\n",
        "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
        "]\n",
        "response=chat(messages)\n",
        "\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2grf7I8AJ_hK"
      },
      "outputs": [],
      "source": [
        "# Import prompt and define PromptTemplate\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are an expert data scientist with an expertise in building deep learning models. \n",
        "Explain the concept of {concept} in a couple of lines\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"concept\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vcz7Q9Y-KFvI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nAn autoencoder is a type of artificial neural network that is used to learn a compressed representation of input data. It works by learning to reconstruct its input data through a series of layers, with the aim of reducing the dimensionality of the data while still preserving its important features.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run LLM with PromptTemplate\n",
        "\n",
        "llm(prompt.format(concept=\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dm78i-rUKXIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "An autoencoder is a type of artificial neural network that attempts to reconstruct its own input. It is used for unsupervised learning, where the goal is to compress the input data into a lower dimensional representation, known as an encoding, and then to reconstruct the input from the encoding.\n"
          ]
        }
      ],
      "source": [
        "# Import LLMChain and define chain with language model and prompt as arguments.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B6MF4-nMKul3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "An autoencoder is a type of artificial neural network that helps to reduce the amount of data needed to represent a certain type of data. It works by taking a large set of data, such as images, and compressing it down into a smaller set of features that still accurately represent the original data.\n",
            "\n",
            "To explain how an autoencoder works, let’s imagine that we have a lot of images of different cats. To make it easier to store and process these images, we can use an autoencoder to compress them.\n",
            "\n",
            "The autoencoder starts by taking the images and breaking them down into smaller parts (like pixels). It then looks for patterns in the pixels, looking for things like edges, shapes, and colors. Once it has identified these patterns, it can create a code that represents them. This code is the autoencoder’s “compressed” version of the original image.\n",
            "\n",
            "The autoencoder then takes this code and uses it to recreate the original image. This is done by taking the code and turning it back into the smaller parts (like pixels) that were used to create the code. The autoencoder then uses these parts to recreate the\n"
          ]
        }
      ],
      "source": [
        "# Define a second prompt \n",
        "\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"ml_concept\"],\n",
        "    template=\"Turn the concept description of {ml_concept} and explain it to me like I'm five in 500 words\",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
        "print(chain_two.run(\"autoencoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SkJKFyk1K-MO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "An autoencoder is a type of artificial neural network that learns to copy its input to its output. It consists of two parts: an encoder, which transforms the input into a hidden representation, and a decoder, which reconstructs the input from the hidden representation. The purpose of autoencoders is to compress the input data into a lower dimensional representation, while still preserving key information.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "An autoencoder is a type of machine learning tool that can help us understand data better. It's like a special kind of game where the computer has to copy its input to its output. To do this, the autoencoder has two parts. \n",
            "\n",
            "The first part is called the encoder. This part takes the data (like pictures, numbers, words, etc.) and turns it into a hidden representation. It's like taking the data and putting it in a secret code! \n",
            "\n",
            "The second part is called the decoder. This part takes the hidden representation and turns it back into the original data. It's like taking the secret code and turning it back into the original data. \n",
            "\n",
            "The goal of an autoencoder is to compress the data into a smaller representation, while still preserving the important information. This can help us make sense of data better, because it helps us figure out which parts of the data are important and which parts are not. \n",
            "\n",
            "For example, if we have a lot of pictures of cats, an autoencoder can help us figure out the important features of a cat that make it look like a cat. This way, we can better understand cats and other images better\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "An autoencoder is a type of machine learning tool that can help us understand data better. It's like a special kind of game where the computer has to copy its input to its output. To do this, the autoencoder has two parts. \n",
            "\n",
            "The first part is called the encoder. This part takes the data (like pictures, numbers, words, etc.) and turns it into a hidden representation. It's like taking the data and putting it in a secret code! \n",
            "\n",
            "The second part is called the decoder. This part takes the hidden representation and turns it back into the original data. It's like taking the secret code and turning it back into the original data. \n",
            "\n",
            "The goal of an autoencoder is to compress the data into a smaller representation, while still preserving the important information. This can help us make sense of data better, because it helps us figure out which parts of the data are important and which parts are not. \n",
            "\n",
            "For example, if we have a lot of pictures of cats, an autoencoder can help us figure out the important features of a cat that make it look like a cat. This way, we can better understand cats and other images better\n"
          ]
        }
      ],
      "source": [
        "# Define a sequential chain using the two chains above: the second chain takes the output of the first chain as input\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain specifying only the input variable for the first chain.\n",
        "explanation = overall_chain.run(\"autoencoder\")\n",
        "print(explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([explanation])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"An autoencoder is a type of machine learning tool that can help us understand data better. It's like\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "\n",
        "texts[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.03901302437936434, 0.040125913876690324, 0.013684441321404882, 0.031222784859566418, 0.031841058251249305, 0.011994495044215746, -0.01605448870197422, 0.007831457062940224, 0.0231440178811595, 0.003951794463796237, -0.045587327284351505, -0.023308889916373865, 0.012880686657275193, 0.01853788455901554, 0.02209295330156311, -0.003676147894872831, 0.0334691777480637, 0.0026688782936413425, 0.026111727553534133, -0.005358365824515124, 0.015796873702230017, -4.1499963074787335e-05, 0.06796880804452361, -0.019166462103653355, 0.04892599950161975, 0.031264003334031294, 0.012406676994896811, 0.045133925927882984, -0.013684441321404882, -0.017373470571624597, -0.020351484396954164, 0.009536860500884332, 0.031511310455530274, 0.034664504194319434, 0.040290787774549836, 0.0210831071964316, 0.03668419640458245, -0.010072696943637459, -0.023844726359126992, -0.019073721001768663, 0.008001482105954631, -0.003717366136507066, -0.004065144802913367, 0.0204751398203488, -0.035509478264236574, -0.01742499319904441, -0.07246159009622787, 0.0024524826996845904, -0.019114939476233543, 0.06273409717774184, 0.02104189058461187, 0.04179525371061474, 0.004791615525913339, 0.029182484343393537, 0.007244097992767286, -0.04863747204301075, 0.019712602699361415, -0.030006848244755666, -0.03981677811217146, -0.010778558429404991, 0.036168966405094045, -0.020485443973303732, 0.00043536719704840644, 0.03202654045501868, -0.07608879349739542, -0.035880438946485044, 0.017455905657909207, -0.005956029513304282, -0.0023700464492467637, -0.07518199078445838, 0.007450188968107818, 0.06475378566271456, 0.0021085683234670334, -0.05148153001728104, 0.01171627266988425, -0.017703216504698478, 0.008660973972102392, 0.024421781276344996, 0.03324247520718429, -0.008825846938639333, 0.02623538297692877, -0.0035756786782719413, 0.02130980787466586, -0.022443307540546856, -0.016621237603592146, 0.037900131156748056, -0.011201045464363563, -0.04156855116973533, 0.001134144490347932, -0.035159122162607685, 0.05024498323391527, 0.013622614541030137, -0.05325391138075478, 0.01628118751756333, 0.020423617192928987, -0.012056322755913064, 0.040785405742838086, 0.043691288634837976, -0.04591707135478024, 0.02116554414536136, -0.005899354343745717, -0.04826650763547199, -0.03598348792661496, -0.035076685213677926, -0.011046476650781555, 0.03402562063408154, -0.029677102311681785, -0.01526103725947689, -0.011561704787624817, -0.0008713784618641571, 0.020413313039974054, 0.005652045359601593, 0.016755197179941714, -0.025246145177707124, 0.04027017946863997, 0.05329512799257451, 0.021928081266348744, 0.06965875618435789, -0.011335004109390558, 0.041176978456286706, -0.005657197436079059, 0.025678936365620627, -0.011757491144349128, -0.00466023245346379, 0.021866254485974, 0.008805237701406893, 0.007115291424217757, -0.020083567106900173, -0.0017234358220305631, 0.015364083445639085, 0.05688111105663204, 0.01434393225623007, -0.018187530320031793, 0.013210432590349073, -0.0028414793748944823, 0.007960264562812326, -0.009634753679246488, 0.026400255012143135, 0.06846342228752157, -0.028770301461389897, -0.008918587109201449, -0.0036503865811629253, 1.4631655161274798e-05, -0.006630977608884443, -0.014797332681376013, 0.05898324021582481, -0.0015933408851157031, 0.03217080232167804, 0.00635275476889166, -0.016683066246612036, 0.006759784177433971, -0.017466211673509285, -0.008609451344682582, 0.040002260315940834, 0.0588183663179653, 0.019537424648546967, -0.03839474912503631, 0.034953031652928436, 0.01100525910763925, -0.021371634655040606, 0.007007093627239382, 0.007743868968855574, -0.03759099539222919, 0.038477186073966066, -0.01763108370872365, -0.03961068760249221, -0.01683763412887147, -0.011912059026608563, 0.005610826885136714, 0.015436215310291336, 0.006517627269767313, 0.04092967133478773, -0.04027017946863997, 0.007125596042833977, 0.045875854742960506, 0.00720803206044116, 0.034788157755068924, -0.04177464167941458, -0.04043505336649948, 0.03769404064706881, 0.05263563985171705, 0.024916401107278392, 0.026544518741447636, 0.032850902493735665, 0.0002865952844108004, -0.01160292233076712, 0.04909087339947926, -0.009779017408550991, 0.001242342287326308, 0.017651693877278666, 0.019516816342637102, -0.037384904882549946, 0.0396725162455121, 0.015024033359610271, -0.01924889905258311, 0.002185852497427394, 0.004807072221007025, -0.04196012388318396, -0.026359036537678255, -0.004126972048949397, 0.04488661508109371, 0.005064685823767368, 0.019578643123011847, 0.03316003825825453, 0.01845544761008578, 0.025307973820727015, 0.027739847050348525, -0.0018986131743530799, -0.0026894872980431383, -0.0076356711718771975, -0.017136465740435404, -0.026874264674521517, 0.017404383030489395, -0.012860077420042753, 0.0022657127096264874, 0.01720859667376508, 0.007166814051637569, -0.04801920051397301, 0.03293333944266542, 0.012581855045711257, -0.05514994630497802, -0.036168966405094045, 0.0013820977168823828, 0.0021588031645981215, -0.02844055552831602, -0.0077644777404267265, -0.04086784269176784, -0.0025529521491161234, -0.037446733525569834, 0.041692208455775114, 0.030460247738579034, -0.009804778722260895, 0.0021742598596918078, 0.049626707979587244, 0.012159368010752687, -0.0075841480787961, -0.01495190149495802, 0.020732752957447854, -0.020320571938089366, -0.009655362916478928, 0.02619416450246389, -0.051687620526960285, 0.0024614992991814437, 0.03872449692075534, -0.02813141976379715, 0.008501253082042918, 0.004825105420000731, -0.011046476650781555, 0.023927163308056748, 0.027265837387970143, -0.0032536615584061904, -0.03649871420081307, 0.06763906024880459, -0.051852490699529505, 0.017136465740435404, 0.007501712061188917, -0.03441719334753016, -0.01974351702087136, 0.05535604053994756, 0.016549106670262468, -0.002234799086608472, 0.04107393320144709, -0.008645516811347419, -0.02102128041605686, 0.017229206842320096, 0.0033773160504782522, -0.006971027694913257, 0.022690618387336128, 0.05280051002428627, 0.0016551682475670557, 0.013859618440896756, 0.023288281610464, 0.014745810053956202, -0.003274270562807986, -0.008769171303419481, -0.011510181228882432, 0.026070509079069253, -0.006667043541210568, -0.06520719074447337, 0.022896708897015373, -0.037508558443299436, 0.012994036996392322, 0.012097541230377942, -0.019053110833213652, 0.009902671900623052, 0.025349192295191895, 0.021000672110146994, -0.043485198125158726, -0.005077566480622321, 0.01464276479911658, 0.04148611422080558, 0.030151111974060167, -0.014426369205159828, -0.19240654985161107, 0.010623990547145558, -0.03159374740446003, 0.040414441335299325, -0.008315770878273539, -0.0034597525337467226, -0.03792074318794822, 0.03270664062707631, 0.07275012128012717, -0.04534001643756223, 0.03631323199704369, 0.040723580825108484, 0.004567491351579101, 0.006589759134419564, 0.01277764140243557, 0.03058390316197367, 0.04632925237413873, -0.0036735718566340975, -0.002556816206474223, -0.02551406433040626, 0.003920881073608865, 0.022195998556402734, -0.023947773476611763, 0.01226241326559231, -0.06454769515303532, 0.010871299531289682, 0.011489572922972565, -0.015394996835826458, -0.03569496046800596, 0.02776045535625839, 0.03752917047449959, -0.03555069487605631, 0.022814271948085618, -0.013663832084172442, -0.05296538392214578, -0.013684441321404882, 0.03662236776156256, 0.021474679909880227, -0.026255991282838634, 0.013849314287941823, 0.008697039438767231, -0.0393839887869031, -0.00906285083850595, 0.009346226220637487, -0.015116773530172389, -0.030130501805505153, -0.02835812044203141, 0.009274094355985236, 0.027059746878290897, -0.012746727080925625, 0.020279353463624486, -0.0030321136551413287, -0.016064792854929153, -0.043320324227299215, -0.09983047087639249, 0.03509729351958779, 0.05144030968017101, -0.017332252097159717, 0.007151357356543883, -0.004812224763145778, 0.017054028791505648, 0.012509723181059007, -0.03546825792712655, -0.03942520539872283, 0.01646666972133271, 0.04880234594087026, 0.049750365265627025, 0.041300632017036196, 0.0038023786580142693, 0.04422712694023625, -0.006569150362848411, -0.003658114928709768, 0.0316143557103699, 0.030604511467883535, 0.028481774002780895, -0.05877714970614556, 0.005806613707522314, -0.0512754357823115, 0.01918707040956322, 0.0105415535982158, -0.006146663793551128, -0.005755090614441216, 0.014920987173448075, -0.022360872454262246, 0.07373935721670366, -0.07814969859418787, 0.016023574380464273, 0.00740381888282676, -0.043196670666549725, 0.0062239477346808444, -0.06401185684763705, 0.04406225304237673, 0.03633384030295356, -0.025060664836582893, 0.00026840131585781693, 0.032644811984056415, 0.014601546324651701, 0.07365691654248362, -0.0044258041261746196, 0.01683763412887147, 0.0005161935108985163, -0.03678724165942208, -0.00037869220211282444, 0.003730246793362019, 0.043237887278369455, -0.02965649214312677, -0.04855503509408099, -0.020495748126258664, -0.033984404022261806, 0.01756925692834891, 0.013344391235376068, -0.020361790412554242, -0.010994954023361744, -0.06368211650249861, -0.03192349520017906, 0.029821366040986286, -0.016909765062201147, -0.02984197434689615, -0.009897519824145586, 0.0007110139114909648, -0.01868214828832004, -0.02021752668324974, -0.009505947110696961, 0.02839933705385114, -0.057911567330318554, 0.03602470453843469, -0.06413551413367682, -0.008861912405304172, -0.01287038250432026, -0.05861227580828605, 0.017734128963563276, 0.01466337403634902, -0.007888132698160076, -0.027801673830723267, -0.02526675534626214, -0.00791389401186998, -0.03379892181849243, -0.047524582545684764, -0.011468963685740127, -0.009954194528042864, 0.00580146116538356, 0.0068937432881222525, -0.04261961574933172, 0.045752197456920725, 0.0022708650189345973, 0.012818858945577875, 0.009402900924534763, 0.05296538392214578, 0.019403466934842545, 0.015075555987030084, -0.015096165224262522, -0.010943431395941932, 0.030068675025130408, -0.02080488575342268, 0.02623538297692877, 0.011056781735059062, -0.00027790080610911076, -0.03621018674220407, -0.0023146592988075657, -0.007759325663949259, 0.010799167666637431, -0.00989236774766812, -0.008346685199783484, 0.04591707135478024, 0.0052707767991079, 0.019496208036727237, -0.059972476152401304, -0.03888937081861485, 0.005734481842870063, -0.004044535565680927, -0.012489113943826567, -0.030934257400957416, 0.008125137529349267, -0.022402090928727126, -0.05725207546417079, -0.012901295894507631, 0.014910683020493143, 0.0024035361105035125, 0.058035220891068044, 0.0044953594869268495, 0.006141511251412374, 0.013993578017246324, 0.01969199439345155, 0.02759558332104402, 0.004356248299761102, 0.02629720975730351, 0.060302223948120334, -0.017703216504698478, -0.011664750042464438, 0.014993119038100326, 0.0021974451351629803, -0.021783817537044243, -0.011046476650781555, -0.01263337767313107, -0.018506970237505593, -0.017703216504698478, 0.00890313087976905, 0.026833046200056637, -0.02712157365866564, -0.026214772808373754, 0.016992202011130903, -0.0016757773683841732, -0.0756353884156366, -0.0067340228637240655, -0.004330486986051196, -0.02080488575342268, -0.09941828985703399, -0.04422712694023625, -0.05547969410069705, 0.02782228399927828, 0.06817489855420286, 0.023411935171213486, 0.04933818052097824, -0.004644775758370104, 0.01978473549533624, 0.011139217752666245, 0.013292868607956258, 0.012653986910363508, 0.01591022497266972, 0.03159374740446003, 0.0346851125002293, 0.020145393887274918, -0.005971486208397967, 0.0023236758983044186, 0.029264919429678144, -0.022690618387336128, 0.013828705050709383, 0.016363624466493087, 0.012942514368972511, -0.02860542942617553, 0.01608540116083902, -0.014230582848435515, -0.043732508971948, 0.009779017408550991, -0.005031196395341263, 0.024957617719098123, -0.01051064020802843, -0.02980075587243127, 0.04867869238012077, 0.0313258282517609, -0.013313477845188696, -0.016806719807361523, -0.047565799157504494, 0.047483362208574735, 0.01990838905608573, -0.002532342911883684, -0.01610601132939403, 0.06384699040035811, -0.013426828184305826, -0.011396831821087876, 0.005518086248913311, -0.010335463088536556, -0.012550940724201312, -0.01282916402985538, -0.020042348632435297, -0.030109893499595287, 0.02176320736848923, 0.0054098884519349355, -0.023597417374982867, -0.027142183827220653, -0.020969757788637047, -0.006254861590529503, 0.006244556971913283, 0.0706479921209344, 0.015930833278579585, 0.042825706259010964, 0.022031126521188365, 0.03792074318794822, -0.008439426301668175, 0.026833046200056637, -0.026730000945217016, 0.03342795741095367, 0.03742612149436968, 0.03792074318794822, 0.03233567621953755, -0.04632925237413873, -0.0023198116081156756, -0.005098175717854761, 0.0110773909722915, -0.05754060292277979, 0.007836610070740263, -0.029017610445534022, -0.0015727318807139071, 0.026317819925858525, -0.023721072798377502, 0.029780147566521406, -0.018465751763040713, -0.0793450324910242, 0.00816635507249157, 0.011922363179563496, -0.043691288634837976, -0.0004904321389809498, -0.035962875895414796, -0.01287038250432026, 0.009706885543898739, -0.00626001366700697, 0.011819317924723873, -0.021206762619826236, 0.012489113943826567, 0.027863500611098012, 0.01738377472457953, -0.04670021678167749, 0.050286199845735007, -0.027801673830723267, -0.00661552044812947, 0.0014838550690179605, -0.008398207827203295, 0.062321916158383346, -0.0030939409011773596, -0.028893956884784532, -0.01369474640568239, -0.02421569076666575, 0.013498960048958076, -0.05885958665507532, -0.027698628575883646, -0.008702191515244697, -0.0378176942078183, -0.05947785818411305, 0.016930375230756158, 0.02969771061759165, -0.031181566385101542, 0.07270889721772684, -0.012571549961433752, -0.05931298428625354, 0.03649871420081307, -0.02656512891000265, 0.006600063753035784, -0.05428436765444131, 0.024566045005649496, -0.04204256083211372, 0.027245229082060275, -0.015848396329649826, 0.015291951580986835, 0.016950983536666027, -0.0026559976367863895, 0.0652484073562931, 0.0007503000080308282, -0.022443307540546856, -0.009835692112448268, 0.028213856712726908, 0.04119758676219657, 0.013035254539534627, -0.005719024682115091, -0.0018548188944801116, -0.016384232772402953, 0.004443836859507039, 0.0075841480787961, 0.004840562115094417, 0.03905424099118407, 0.009748104018363618, 0.00910406931297083, 0.008341533123306018, 0.047071181189216244, -0.040332004386369566, -0.017084943113015595, 0.029924411295825907, 0.05630405613941403, 0.030151111974060167, 0.037384904882549946, -0.007470798205340258, -0.014024491407433696, 0.01275703216520313, -0.02872908298692502, -0.06351724260463909, -0.014745810053956202, 0.020444225498838852, 0.00846003460757804, 0.06104414903790756, -0.03149070214962041, 0.024133253817735994, 0.06331115209495984, -0.01701281031704077, 0.01716738006194535, 0.030233547060344777, -0.01576596124336522, -0.030789993671652915, -0.00908346007573839, -0.0484313815333315, 0.023514982288698257, 0.02306158093222974, 0.00528108141772412, 0.05873592936903554, -0.038353532513216576, -0.0015431062768152583, 0.020166002193184783, -0.015024033359610271, 0.03544764962121669, 0.0032871512196629388, -0.03054268468750879, 0.02831690196756653, -0.05317147443182503, 0.023226454830089255, -0.047648236106434254, -0.0022129020630873098, -0.006878286593028566, -0.027987156034492647, 0.008176660156769077, 0.0371788143728707, -0.006852525279318661, -0.00202484405390984, 0.003758584378141301, -0.009464728636232081, 0.04645290966017851, 0.008305466725318606, -0.012416982079174316, -0.013571091913610327, -0.022876098728460362, 0.028626037732085396, 0.07023581110157591, -0.02712157365866564, 0.03952825065356245, -0.0070843775683690985, 0.026977309929361138, -0.024009600256986504, -0.007491407442572697, 0.022072344995653245, 0.01597205175304446, 0.011922363179563496, 0.04352641473697846, 0.05976638564272206, 0.05040985713177479, -0.03157313909855017, -0.0203308760910443, 0.013220736743304007, 0.03627201538522396, 0.01074764503921762, 0.0325417667292168, -0.024833964158348633, 0.08392024776636792, -0.033654659951833074, 0.03367526825774294, -0.01369474640568239, -0.0006562710034420936, 0.01990838905608573, -0.033943183685151784, 0.004309877748818757, -0.024318736021505374, -0.04249596218858223, 0.008748562066187042, 0.026070509079069253, -0.011881145636421191, -0.003758584378141301, -0.010644599784377998, -0.025390408907011625, 0.04278448964719123, -0.08095253995663843, -0.022876098728460362, -0.013550482676377887, 0.023927163308056748, 0.06166242429223559, -0.0220105182152785, -0.003063027278159344, 0.013519568354867941, -0.043485198125158726, 0.001521209136878774, 0.003269118253499876, 0.012097541230377942, 0.05675745749588255, -0.002210325792017933, 0.02928552959823316, 0.03571556877391582, 0.027142183827220653, -0.010098458257347365, -0.017084943113015595, -0.0343347601238907, -0.02835812044203141, 0.03860084336000585, 0.023721072798377502, -0.03602470453843469, 0.02831690196756653, -0.0003091364921146287, -0.020413313039974054, -0.028193246544171893, 0.07171966128115036, -0.0178062617595381, -0.0626516565035218, -0.013509264201913009, -0.019815647954201036, 0.0070946821869853184, 0.01990838905608573, 0.016167838109768774, 0.054119493756581795, -0.04995645577530627, -0.004652503873086304, -0.06054953106961931, -0.004814800801384511, 0.009840844188925734, -0.02957405705684216, 0.0036194729581449096, -0.01687885260333635, -0.04459809134777501, 0.06273409717774184, 0.043361544564409236, 0.01466337403634902, 0.045422453386491986, 0.011912059026608563, -0.00264569301817017, -0.008964957660143795, -0.031758621302319545, 0.006749480024479038, 0.009531708424406865, 0.018805801849069527, -0.029120655700373643, 0.035509478264236574, 0.008125137529349267, 0.019207680578118235, -0.01881610786466961, 0.017960829641797533, -0.043196670666549725, -0.0047091790426448685, -0.046288035762319, -0.0207636672789578, -0.02102128041605686, -0.036725413016402184, -0.023411935171213486, -0.011231958854550935, 0.014446978442392266, -0.006089988623992563, -0.06833977245206238, -0.05444923782701053, 0.00939259677157983, 0.0774902104533304, 0.010186047282754587, -0.005252744065775482, 0.06706200533158659, 0.011829623009001379, -0.030068675025130408, -0.03287151079964553, 0.030893038926492537, 0.005154850887413325, -0.0037147900982683326, 0.0028285987180395296, -0.033695876563652805, 0.040208350825620076, -0.01434393225623007, 0.022443307540546856, -0.01660062929768228, -0.0117884045345365, 0.0105415535982158, -0.032768465544805905, -0.014766419291188642, 0.06211582192341381, 0.047895546953223525, 0.007512016679805136, 0.0089752627444213, 0.03344856571686353, -0.003962099082412456, 0.032727248932986175, -0.015539260565130959, -0.02145407160397036, 0.0023030666610719796, 0.03274785723889604, 0.01337530462556344, 0.04818407441183253, -0.010242721986651866, -0.009737798934086111, 0.007079225491891632, 0.0013421674943675142, -0.008253944097898794, -0.051976147985569286, 0.025946855518319763, -0.02213417177602799, 0.04389737914451722, -0.006012704682862846, -0.018743975068694785, -0.030192330448525043, 0.0005210237572191236, -0.026317819925858525, -0.005626284045891687, 0.022525744489476616, -0.014982814885145393, 0.038435969462146335, -0.022937927371480253, 0.0136020053037977, 0.04270205269826148, -0.0024177047864778318, 0.007213184602579914, 0.017095247265970528, -0.010912518005754561, 0.020732752957447854, -0.007919046088347446, 0.020485443973303732, -0.006038465996572751, -0.06083805852822831, -0.014993119038100326, -0.03072816689127817, -0.002227070739061629, -0.12052200722202061, 0.012581855045711257, -0.04678265373060724, -0.009253485118752796, 0.026255991282838634, -0.004943607369934039, 0.0397343411632417, -0.024277517547040495, -0.0033129125333728445, -0.0151682961575922, -0.007213184602579914, -0.043320324227299215, 0.0038023786580142693, 0.003498394504311581, 0.0070843775683690985, 0.0013447436490215692, -0.03464389588840957, -0.011304090719203186, -0.009160744016868106, 0.008083919054884387, -0.0591068937765743, 0.008619755497637514, -0.00942866223824467, -0.0047091790426448685, 0.0552736035910178, -0.06087927886533834, 0.07798483214690895, -0.0337577052066727, -0.020928539314172167, 0.02306158093222974, -0.00369675713210527, 0.03864205997182558, 0.022999754151854998, -0.02388594483359187, 0.009016480287563605, 0.008655821895624926, -0.04245474185147221, -0.012097541230377942, 0.017538342606838963, -0.05189371103663953, -0.005378974596086277, 0.02504005466802788, -0.0027590431244566556, 0.023824118053217127, 0.03594226758950493, 0.005641740740985373, -0.11945033806180465, -0.005971486208397967, -0.02098006194159198, 0.051770057475890044, 0.006084836547515096, 0.02555528280487114, 0.015673220141480527, -0.013200127506071567, -0.005378974596086277, 0.0325417667292168, 0.03878632183848493, -0.0017324523051120944, 0.034066840971191566, -0.001769806372972908, -0.015487737937711148, -0.021866254485974, 0.09760469188174052, -0.03538582097819679, -0.043114233717619965, -0.005384127138225029, 0.02324706313599912, 0.017826870065447965, 0.013292868607956258, 0.0009969650990305906, -0.03752917047449959, 0.01596174760008953, 0.019413771087797477, -0.0011186876788389245, 0.02551406433040626, -0.02074305711040279, -0.02291731720292524, 0.0703594609370351, 0.0014168755136738198, -0.0325417667292168, 0.002520750274148098, -0.042145606086953336, -0.001848378566052635, 0.02361802754353788, -0.029120655700373643, -0.043402761176228974, 0.007439884815152885, 0.015024033359610271, 0.062198258872343565, -0.040332004386369566, -0.0025800014819453957, 0.043073017105800235, 0.015930833278579585, 0.021392244823595617, -0.04202195252620385, -0.04604072491552973, 0.0011933955817299083, -0.13478350625461122, 0.05885958665507532, -0.029780147566521406, 0.021845644317418988, 0.010716731649030248, 7.120604270254501e-05, -0.032644811984056415, -0.019259203205538044, 0.02924431112376828, -0.0110773909722915, -0.006399125319834004, 0.0359010509776852, -0.03293333944266542, -0.0418776869342542, -0.0063836681590790315, -0.03068694841681329, -0.00627031828562319, -0.018610015492345217, -0.05296538392214578, -0.02831690196756653, 0.022443307540546856, -0.005093023641377294, 0.0048895087042754954, -0.022855490422550494, 0.002243815686105325, -0.006548541125615972, 0.05024498323391527, -0.021928081266348744, -0.015106469377217454, 0.03513851385669782, 0.035200338774427416, -0.0011669902584603192, -0.02130980787466586, 0.02757497315248901, 0.002746162467601703, -0.0397343411632417, -0.018424533288575837, -0.04674143711878751, -0.002712672573514311, 0.0452987998257425, -0.024339346190060385, -0.018939761425419095, 0.001250070634873151, 0.018692452441274973, 0.0699472799176766, 0.004925574636601621, -0.031181566385101542]\n"
          ]
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [],
      "source": [
        "# Import and initialize Pinecone client\n",
        "\n",
        "import os\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),  \n",
        "    environment=os.getenv('PINECONE_ENV')  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [],
      "source": [
        "# Upload vectors to Pinecone\n",
        "\n",
        "index_name = \"langchain-quickstart\"\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content='autoencoder has two parts.', metadata={}), Document(page_content=\"An autoencoder is a type of machine learning tool that can help us understand data better. It's like\", metadata={}), Document(page_content='For example, if we have a lot of pictures of cats, an autoencoder can help us figure out the', metadata={}), Document(page_content='The goal of an autoencoder is to compress the data into a smaller representation, while still', metadata={})]\n"
          ]
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "\n",
        "query = \"What is magical about an autoencoder?\"\n",
        "result = search.similarity_search(query)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4Ogz8luZNRnJ"
      },
      "outputs": [],
      "source": [
        "# Import Python REPL tool and instantiate Python agent\n",
        "\n",
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.llms.openai import OpenAI\n",
        "\n",
        "agent_executor = create_python_agent(\n",
        "    llm=OpenAI(temperature=0, max_tokens=1000),\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BVHMDj0sNi09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to solve a quadratic equation\n",
            "Action: Python REPL\n",
            "Action Input: import numpy as np\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I can use the numpy function to solve the equation\n",
            "Action: Python REPL\n",
            "Action Input: np.roots([3,2,-1])\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: (-1.0, 0.3333333333333333)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'(-1.0, 0.3333333333333333)'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Execute the Python agent\n",
        "\n",
        "agent_executor.run(\"Find the roots (zeros) if the quadratic function 3 * x**2 + 2*x -1\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
